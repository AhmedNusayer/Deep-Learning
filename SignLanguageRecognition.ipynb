{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout,Flatten\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from scipy.linalg import eigh\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "path = 'F:\\\\3-1\\\\RESIZED_DATASET'\n",
    "myList = os.listdir(path)\n",
    "print(len(myList))\n",
    "noOfClasses = len(myList)\n",
    "images=[]\n",
    "classNo = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,noOfClasses):\n",
    "    myPicList = os.listdir(path+\"/\"+str(x))\n",
    "    for y in myPicList:\n",
    "        curImg = cv2.imread(path+\"/\"+str(x)+\"/\"+y)\n",
    "        curImg = cv2.resize(curImg,(128,128))\n",
    "        images.append(curImg)\n",
    "        classNo.append(x)\n",
    "    #print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11061\n",
      "11061\n"
     ]
    }
   ],
   "source": [
    "print(len(images))\n",
    "print(len(classNo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11061, 128, 128, 3)\n",
      "(11061,)\n"
     ]
    }
   ],
   "source": [
    "images = np.array(images)\n",
    "classNo = np.array(classNo)\n",
    "print(images.shape)\n",
    "print(classNo.shape)\n",
    "testRatio=0.2\n",
    "validationRatio=0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(images,classNo,test_size=testRatio)\n",
    "X_train,X_validation,y_train,y_validation = train_test_split(X_train,y_train,test_size=validationRatio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7078, 128, 128, 3)\n",
      "(1770, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[172, 181, 188, 181, 146, 197, 196, 183, 184, 184, 190, 188, 179, 189, 178, 175, 204, 195, 192, 202, 196, 180, 194, 189, 198, 192, 176, 195, 177, 181, 194, 203, 202, 177, 181, 178, 177, 184]\n"
     ]
    }
   ],
   "source": [
    "numOfSamples= []\n",
    "for x in range(0,noOfClasses):\n",
    "    #print(len(np.where(y_train==x)[0]))\n",
    "    numOfSamples.append(len(np.where(y_train==x)[0]))\n",
    "print(numOfSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessing(img):\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.equalizeHist(img)\n",
    "    img = img/255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(list(map(preProcessing,X_train)))\n",
    "X_test = np.array(list(map(preProcessing,X_test)))\n",
    "X_validation = np.array(list(map(preProcessing,X_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7078, 128, 128)\n",
      "(7078, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)\n",
    "X_validation = X_validation.reshape(X_validation.shape[0],X_validation.shape[1],X_validation.shape[2],1)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGen = ImageDataGenerator(width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             zoom_range=0.2,\n",
    "                             shear_range=0.1,\n",
    "                             rotation_range=10)\n",
    "dataGen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7078, 38)\n"
     ]
    }
   ],
   "source": [
    "y_train = to_categorical(y_train,noOfClasses)\n",
    "y_test = to_categorical(y_test,noOfClasses)\n",
    "y_validation = to_categorical(y_validation,noOfClasses)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageDimensions=(128,128,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 124, 124, 60)      1560      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 120, 120, 60)      90060     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 60, 60, 60)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 58, 58, 30)        16230     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 30)        8130      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 30)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28, 28, 30)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 23520)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               11760500  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 38)                19038     \n",
      "=================================================================\n",
      "Total params: 11,895,518\n",
      "Trainable params: 11,895,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def myModel():\n",
    "    noOfFilters = 60\n",
    "    sizeOfFilter1 = (5,5)\n",
    "    sizeOfFilter2 = (3, 3)\n",
    "    sizeOfPool = (2,2)\n",
    "    noOfNodes= 500\n",
    " \n",
    "    model = Sequential()\n",
    "    model.add((Conv2D(noOfFilters,sizeOfFilter1,input_shape=(imageDimensions[0],\n",
    "                      imageDimensions[1],1),activation='relu')))\n",
    "    model.add((Conv2D(noOfFilters, sizeOfFilter1, activation='relu')))\n",
    "    model.add(MaxPooling2D(pool_size=sizeOfPool))\n",
    "    model.add((Conv2D(noOfFilters//2, sizeOfFilter2, activation='relu')))\n",
    "    model.add((Conv2D(noOfFilters//2, sizeOfFilter2, activation='relu')))\n",
    "    model.add(MaxPooling2D(pool_size=sizeOfPool))\n",
    "    model.add(Dropout(0.5))\n",
    " \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(noOfNodes,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(noOfClasses, activation='softmax'))\n",
    " \n",
    "    model.compile(Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    " \n",
    "model = myModel()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSizeVal = 50\n",
    "epochsVal = 10\n",
    "stepsPerEpochVal = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7078 samples, validate on 1770 samples\n",
      "Epoch 1/10\n",
      "7078/7078 [==============================] - 256s 36ms/step - loss: 3.3499 - accuracy: 0.1065 - val_loss: 2.8282 - val_accuracy: 0.2333\n",
      "Epoch 2/10\n",
      "7078/7078 [==============================] - 181s 26ms/step - loss: 2.6635 - accuracy: 0.2732 - val_loss: 2.2671 - val_accuracy: 0.3904\n",
      "Epoch 3/10\n",
      "7078/7078 [==============================] - 181s 26ms/step - loss: 2.0267 - accuracy: 0.4217 - val_loss: 1.8911 - val_accuracy: 0.4695\n",
      "Epoch 4/10\n",
      "7078/7078 [==============================] - 181s 26ms/step - loss: 1.5031 - accuracy: 0.5448 - val_loss: 1.7747 - val_accuracy: 0.5164\n",
      "Epoch 5/10\n",
      "7078/7078 [==============================] - 181s 26ms/step - loss: 1.1325 - accuracy: 0.6527 - val_loss: 1.6062 - val_accuracy: 0.5384\n",
      "Epoch 6/10\n",
      "7078/7078 [==============================] - 181s 26ms/step - loss: 0.8433 - accuracy: 0.7342 - val_loss: 1.6687 - val_accuracy: 0.5565\n",
      "Epoch 7/10\n",
      "7078/7078 [==============================] - 181s 26ms/step - loss: 0.6627 - accuracy: 0.7915 - val_loss: 1.6760 - val_accuracy: 0.5774\n",
      "Epoch 8/10\n",
      "7078/7078 [==============================] - 181s 26ms/step - loss: 0.5170 - accuracy: 0.8302 - val_loss: 1.7710 - val_accuracy: 0.5621\n",
      "Epoch 9/10\n",
      "7078/7078 [==============================] - 181s 26ms/step - loss: 0.4385 - accuracy: 0.8644 - val_loss: 1.6517 - val_accuracy: 0.5689\n",
      "Epoch 10/10\n",
      "5696/7078 [=======================>......] - ETA: 32s - loss: 0.3935 - accuracy: 0.8755"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train, validation_data=(X_validation,y_validation), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.8990095019394382, 0.5666515827178955]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test,y_test,verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    "while True:\n",
    "    success,imgOriginal = cap.read()\n",
    "    img = np.asarray(imgOriginal)\n",
    "    img = cv2.resize(img,(128,128))\n",
    "    img = preProcessing(img)\n",
    "    cv2.imshow(\"Processed Image\",img)\n",
    "    img=img.reshape(1,128,128,1)\n",
    "    classIndex = int(model.predict_classes(img))\n",
    "    #print(classIndex)\n",
    "    predictions = model.predict(img)\n",
    "    probVal = np.amax(predictions)\n",
    "    cv2.putText(imgOriginal,str(classIndex)+\" \"+str(probVal),(50,50),\n",
    "               cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),1)\n",
    "    cv2.imshow(\"Original Image\",imgOriginal)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "newpath='F:\\\\3-1\\\\RESIZED_TESTING_DATA\\\\8\\\\20180714_232511.jpg'\n",
    "image = cv2.imread(newpath)\n",
    "cv2.imshow(\"Image\",image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "newpath='F:\\\\3-1\\\\RESIZED_TESTING_DATA\\\\20\\\\20180716_000301.jpg'\n",
    "while True:\n",
    "    #success,imgOriginal = cap.read()\n",
    "    imgOriginal = cv2.imread(newpath)\n",
    "    img = cv2.imread(newpath)\n",
    "    #img = np.asarray(imgOriginal)\n",
    "    img = cv2.resize(img,(128,128))\n",
    "    img = preProcessing(img)\n",
    "    cv2.imshow(\"Processed Image\",img)\n",
    "    img=img.reshape(1,128,128,1)\n",
    "    classIndex = int(model.predict_classes(img))\n",
    "    #print(classIndex)\n",
    "    predictions = model.predict(img)\n",
    "    probVal = np.amax(predictions)\n",
    "    cv2.putText(imgOriginal,str(classIndex)+\" \"+str(probVal),(50,50),\n",
    "               cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),1)\n",
    "    cv2.imshow(\"Original Image\",imgOriginal)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
