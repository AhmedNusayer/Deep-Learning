{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten digit recognition from MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading train and test data from torchvision dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ba75720755452ba70ec6b579f6221d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5cf6a4bd21f48958d51cc592f0b2895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a784e9d8674304913acaf1afd62155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797562ef7a2e4355895997279d38e364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train = datasets.MNIST('', train=True, download=True, \n",
    "                       transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test = datasets.MNIST('', train=False, download=True,\n",
    "                     transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the datasets into trainset and testset, we will pass 10 dataset in a batch and shuffle them to get of any kind of pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing data. Here we will see 10 data because the batch size of trainset is 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([0, 3, 0, 4, 9, 2, 2, 5, 6, 8])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X,y = data[0][1], data[1][0]\n",
    "#print(X)\n",
    "#print(y)\n",
    "plt.imshow(X.view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0][0][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our data is already scaled. \n",
    "One other think to notice is that whether the data is balanced or not. Balanced data means the proportion of the features are close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
      "0: 9.871666666666666%\n",
      "1: 11.236666666666666%\n",
      "2: 9.93%\n",
      "3: 10.218333333333334%\n",
      "4: 9.736666666666666%\n",
      "5: 9.035%\n",
      "6: 9.863333333333333%\n",
      "7: 10.441666666666666%\n",
      "8: 9.751666666666667%\n",
      "9: 9.915000000000001%\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "\n",
    "for data in trainset:\n",
    "    Xs,ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1\n",
    "        total += 1\n",
    "print(counter_dict)        \n",
    "\n",
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total*100.0}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essential imports for neural network implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our model we will create a class called 'Net' which will inherit from the nn.Module class. 'super().__init__()' is used to initialize the super class along with the current class.\n",
    "\n",
    "This is a fully connected neural network. The first parameter of nn.Linear is the input size and the 2nd parameter is the output size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28,64)\n",
    "        self.fc2 = nn.Linear(64,64)\n",
    "        self.fc3 = nn.Linear(64,64)\n",
    "        self.fc4 = nn.Linear(64,10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
